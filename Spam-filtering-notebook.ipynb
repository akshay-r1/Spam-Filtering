{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1-ML for Cyber Security.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saanfzw0hhCy"
      },
      "source": [
        "# Overview\n",
        "This is a Python notebook that performs spam filtering on the lingspam dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc-1FyIqhfhr"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from os.path import join\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from re import search\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ3MnvDcP318"
      },
      "source": [
        "# Import to disable warnigns. Don't import to see function run with warnings. \n",
        "import warnings; warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9tM836QuSTk"
      },
      "source": [
        "# Data Definition\n",
        "Loading the raw data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKmtmI1CuKQ1",
        "outputId": "e573a89a-7e23-4e89-98d2-e2e5b79876d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#Download data source\n",
        "!wget http://www.aueb.gr/users/ion/data/lingspam_public.tar.gz\n",
        "#Unzip the download. Use the first command if you want to view files inside.\n",
        "#!tar -xvf lingspam_public.tar.gz\n",
        "!tar -xf lingspam_public.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-23 20:01:14--  http://www.aueb.gr/users/ion/data/lingspam_public.tar.gz\n",
            "Resolving www.aueb.gr (www.aueb.gr)... 195.251.255.156\n",
            "Connecting to www.aueb.gr (www.aueb.gr)|195.251.255.156|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://www2.aueb.gr/users/ion/data/lingspam_public.tar.gz [following]\n",
            "--2020-10-23 20:01:14--  http://www2.aueb.gr/users/ion/data/lingspam_public.tar.gz\n",
            "Resolving www2.aueb.gr (www2.aueb.gr)... 195.251.255.138\n",
            "Connecting to www2.aueb.gr (www2.aueb.gr)|195.251.255.138|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11564714 (11M) [application/x-gzip]\n",
            "Saving to: ‘lingspam_public.tar.gz’\n",
            "\n",
            "lingspam_public.tar 100%[===================>]  11.03M  1018KB/s    in 15s     \n",
            "\n",
            "2020-10-23 20:01:30 (775 KB/s) - ‘lingspam_public.tar.gz’ saved [11564714/11564714]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK3lKUXSj5Kx"
      },
      "source": [
        "# Pre Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1ixPyDXhZgT"
      },
      "source": [
        "# reading training data\n",
        "train_emails = []\n",
        "path = 'lingspam_public/lemm_stop/part'\n",
        "train_labels = []\n",
        "spam_counter = 0\n",
        "ham_counter = 0\n",
        "for i in range(1,10):\n",
        "  files = [f for f in os.listdir(path+str(i))]\n",
        "  for each in files:\n",
        "    if each.startswith('spm'):\n",
        "      train_labels.append(0)\n",
        "      spam_counter+=1\n",
        "    else:\n",
        "      train_labels.append(1)\n",
        "      ham_counter+=1\n",
        "    with open(join(path+str(i),each)) as f:\n",
        "      train_emails.append(f.read())\n",
        "\n",
        "train_df = pd.DataFrame(columns = ['emails','labels'])\n",
        "train_df['labels']= train_labels\n",
        "train_df['emails']= train_emails\n",
        "  \n",
        "# reading testing data\n",
        "test_emails = []\n",
        "test_path = 'lingspam_public/lemm_stop/part10'\n",
        "test_labels = []\n",
        "files = [f for f in os.listdir(test_path)]\n",
        "for each in files:\n",
        "  if each.startswith('spm'):\n",
        "    test_labels.append(0)\n",
        "  else:\n",
        "    test_labels.append(1)\n",
        "  with open(join(test_path,each)) as f:\n",
        "    test_emails.append(f.read())\n",
        "\n",
        "test_df = pd.DataFrame(columns = ['emails','labels'])\n",
        "test_df['labels']= test_labels\n",
        "test_df['emails']= test_emails"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_R7DFfw1m7k"
      },
      "source": [
        "# Index retreival of the spam labels\n",
        "spam_columns = np.array(train_df[train_df['labels']==0].index)\n",
        "test_spam_columns = np.array(test_df[test_df['labels']==0].index)\n",
        "ham_columns = np.array(train_df[train_df['labels']==1].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR8NH6PLTTXo",
        "outputId": "cfd0d9de-b5e4-4223-8505-3d93d881c5af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Samples\n",
        "print('Training Samples: ')\n",
        "print(train_df.sample(5))\n",
        "\n",
        "print('\\nTesting Samples: ')\n",
        "print(test_df.sample(5))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Samples: \n",
            "                                                 emails  labels\n",
            "2537  Subject: distribute access linguistic resource...       1\n",
            "2328  Subject: linguistic typology 2 : 1 ( 1998 )\\n\\...       1\n",
            "2519  Subject: anthropological linguistic , vol . 39...       1\n",
            "1187  Subject: call : weisgerber colloquium\\n\\ncall ...       1\n",
            "1328  Subject: semantic / syntax - semantic interfac...       1\n",
            "\n",
            "Testing Samples: \n",
            "                                                emails  labels\n",
            "107  Subject: semantic : il dominio tempo-aspettual...       1\n",
            "264  Subject: honor two keynote speaker\\n\\ninternat...       1\n",
            "195  Subject: vacation !\\n\\nfull detail : http : / ...       0\n",
            "269  Subject: mt special issue slt : reminder\\n\\nre...       1\n",
            "254  Subject: workshop announcement\\n\\ncall papers ...       1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEO25dAv8tgj"
      },
      "source": [
        "## Binomial feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYBoPJ-g8Brx",
        "outputId": "c587c8f1-df15-49e4-96c2-5bcfa808abc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#vectorizer = CountVectorizer(binary=False, lowercase= True, stop_words=stop_words,)\n",
        "stop_words =['_']\n",
        "vectorizer = CountVectorizer(binary=True, lowercase= True, token_pattern=r'\\b[^\\d\\W]{3,}\\b',\n",
        "                             stop_words=stop_words)\n",
        "transformed_data = vectorizer.fit_transform(train_df.emails)\n",
        "\n",
        "#print(vectorizer.get_feature_names())\n",
        "document_vector = transformed_data.toarray()\n",
        "document_df = pd.DataFrame(document_vector).transpose()\n",
        "document_df['spam_count'] = document_df[spam_columns].sum(axis=1)\n",
        "document_df['ham_count'] = document_df[ham_columns].sum(axis=1)\n",
        "\n",
        "# indices represent word index in vocubulary, columns, is the emails\n",
        "print(document_df.head(5))\n",
        "\n",
        "#Test data\n",
        "test_data = vectorizer.transform(test_df.emails)\n",
        "testing_df = pd.DataFrame(test_data.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0  1  2  3  4  5  6  ...  2597  2598  2599  2600  2601  spam_count  ham_count\n",
            "0  0  0  0  0  0  0  0  ...     0     0     0     0     0           4          6\n",
            "1  0  0  0  0  0  0  0  ...     0     0     0     0     0           0          6\n",
            "2  0  0  0  0  0  0  0  ...     0     0     0     0     0           0          2\n",
            "3  0  0  0  0  0  0  0  ...     0     0     0     0     0           1          0\n",
            "4  0  0  0  0  0  0  0  ...     0     0     0     0     0           0          3\n",
            "\n",
            "[5 rows x 2604 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld9bTwS4NdGv"
      },
      "source": [
        "## Term Frequency Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdVe_D_4OGU4",
        "outputId": "8e60f6e3-2172-4338-a6e6-f1cae1073852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "stop_words =['_']\n",
        "#set binary as False to have non-zero terms retain it's original count value\n",
        "vectorizer2 = CountVectorizer(binary=False, lowercase= True, token_pattern=r'\\b[^\\d\\W]{3,}\\b',\n",
        "                             stop_words=stop_words)\n",
        "transformed_data = vectorizer2.fit_transform(train_df.emails)\n",
        "\n",
        "#print(vectorizer.get_feature_names())\n",
        "document_vector = transformed_data.toarray()\n",
        "tf_df = pd.DataFrame(document_vector).transpose()\n",
        "tf_df['spam_count'] = tf_df[spam_columns].sum(axis=1)\n",
        "tf_df['ham_count'] = tf_df[ham_columns].sum(axis=1)\n",
        "#tf_df['spam_count'] = document_df['spam_count']\n",
        "#tf_df['ham_count'] = document_df['ham_count']\n",
        "\n",
        "# indices represent word index in vocubulary, columns, is the emails\n",
        "print(tf_df.sample(5))\n",
        "\n",
        "#Test data\n",
        "tf_test = vectorizer2.transform(test_df.emails)\n",
        "tf_testing_df = pd.DataFrame(tf_test.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0  1  2  3  4  5  6  ...  2597  2598  2599  2600  2601  spam_count  ham_count\n",
            "27612  0  0  0  0  0  0  0  ...     0     0     0     0     0           0          2\n",
            "3707   0  0  0  0  0  0  0  ...     0     0     0     0     0           1          0\n",
            "10730  0  0  0  0  0  0  0  ...     0     0     0     0     0           0         12\n",
            "932    0  0  0  0  0  0  0  ...     0     0     0     0     0           0          6\n",
            "26862  0  0  0  0  0  0  0  ...     0     0     0     0     0           0          1\n",
            "\n",
            "[5 rows x 2604 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH7M7mmQV-py",
        "outputId": "4b64a046-5dd7-4b96-c764-0f21dcb88163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# For sanity check, both vocabularies are equal\n",
        "print(vectorizer.vocabulary_ == vectorizer2.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcE59XRENqeN"
      },
      "source": [
        "#Information Gain- Part1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvHnzTs1vvSl"
      },
      "source": [
        "## Calculating Information Gain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-VC5ltZyNu9"
      },
      "source": [
        "#### **UNCOMMENT AND RUN THIS BEFORE RUNNING THE IG CALCULATION A SECOND TIME OR ANY SUBSEQUENT NUMBER OF TIMES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvVVKEevEPFd",
        "outputId": "4cae591a-a069-4281-9f0c-c62bf18d580a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# if re running IG please run this\n",
        "# undoing laplacian smoothing\n",
        "'''document_df['ham_count'] = document_df['ham_count']-1\n",
        "document_df['spam_count'] = document_df['spam_count']-1\n",
        "spam_counter -= 2\n",
        "ham_counter -= 2\n",
        "#p = (ham_counter)/(spam_counter+ham_counter)\n",
        "total_train_emails -= 4'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"document_df['ham_count'] = document_df['ham_count']-1\\ndocument_df['spam_count'] = document_df['spam_count']-1\\nspam_counter -= 2\\nham_counter -= 2\\n#p = (ham_counter)/(spam_counter+ham_counter)\\ntotal_train_emails -= 4\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp5cuBdyT-EE"
      },
      "source": [
        "#document vector is the vector where each row represents an email, each column \n",
        "#represents the occurence of a word, who's index can be retreived using the vectorizer.vocabulary_\n",
        "IG = []\n",
        "\n",
        "# laplacian smoothing\n",
        "document_df['ham_count'] = document_df['ham_count']+1\n",
        "document_df['spam_count'] = document_df['spam_count']+1\n",
        "spam_counter += 2\n",
        "ham_counter += 2\n",
        "p = (ham_counter)/(spam_counter+ham_counter)\n",
        "total_train_emails = len(train_df) + 4\n",
        "\n",
        "#print(spam_counter+2)\n",
        "#print(ham_counter+2)\n",
        "\n",
        "entropy = -p*np.log2(p) - (1-p)*np.log2(1-p)\n",
        "\n",
        "for i in range(len(document_df)):\n",
        "  #print(i)\n",
        "  #print(document_df['ham_count'][i])\n",
        "  p_Xi_given_x = spam_counter - document_df['spam_count'][i] + ham_counter - document_df['ham_count'][i]\n",
        "  #print(p_Xi_given_x)\n",
        "  #entropy legit word appears\n",
        "  entropy_legit_word_appeared = document_df['ham_count'][i] / total_train_emails\n",
        "  entropy_legit_word_appeared *= np.log2(document_df['ham_count'][i]/(document_df['spam_count'][i]+document_df['ham_count'][i]))\n",
        "\n",
        "  #entropy legit, not appeared\n",
        "  entropy_legit_word_not_appeared = (ham_counter - document_df['ham_count'][i])/total_train_emails\n",
        "  entropy_legit_word_not_appeared *= np.log2((ham_counter - document_df['ham_count'][i])/p_Xi_given_x)\n",
        "                                                                                                    \n",
        "  #entropy spam, word appeared\n",
        "  entropy_spam_word_appeared = document_df['spam_count'][i]/total_train_emails\n",
        "  entropy_spam_word_appeared *= np.log2(document_df['spam_count'][i]/(document_df['spam_count'][i]+document_df['ham_count'][i]))\n",
        "\n",
        "  #entropy spam, word not appeared\n",
        "  entropy_spam_word_not_appeared = (spam_counter - document_df['spam_count'][i])/total_train_emails\n",
        "  entropy_spam_word_not_appeared *= np.log2((spam_counter - document_df['spam_count'][i])/p_Xi_given_x)\n",
        "\n",
        "  infogain = entropy + entropy_legit_word_appeared + entropy_legit_word_not_appeared + entropy_spam_word_appeared + entropy_spam_word_not_appeared\n",
        "  #print(infogain)\n",
        "  IG.append(infogain)\n",
        "  \n",
        "document_df['IG'] = IG\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXkE9OWDWqE4"
      },
      "source": [
        "### Check IG Values are non negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5h8R99oU7UL",
        "outputId": "31ab552d-dbc2-496d-9489-b37d914630ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(document_df['IG']>0).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True    44864\n",
              "Name: IG, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCkHrQvf56_B"
      },
      "source": [
        "## N largest IG features (N=10,100,1000)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkegZ3HN3ZRQ"
      },
      "source": [
        "document_df['IG'] = document_df['IG'].fillna(0)\n",
        "ten_largest = document_df.nlargest(10,'IG')\n",
        "hundred_largest = document_df.nlargest(100,'IG')\n",
        "thousand_largest = document_df.nlargest(1000,'IG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46jst4ri49V7"
      },
      "source": [
        "key_list = list(vectorizer.vocabulary_.keys()) \n",
        "val_list = list(vectorizer.vocabulary_.values()) \n",
        "ten_largest_words = []\n",
        "hundred_largest_words = []\n",
        "thousand_largest_words = []\n",
        "for each in ten_largest.index:\n",
        "  ten_largest_words.append(key_list[val_list.index(each)])\n",
        "for each in hundred_largest.index:\n",
        "  hundred_largest_words.append(key_list[val_list.index(each)])\n",
        "for each in thousand_largest.index:\n",
        "  thousand_largest_words.append(key_list[val_list.index(each)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cxkG5mJ5FQT",
        "outputId": "4e894285-2fef-48a9-db37-79cf12015407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print('Ten largest IG features :' )\n",
        "print(*ten_largest_words,sep=', ')\n",
        "print('Hundred largest IG features :' )\n",
        "print(*hundred_largest_words,sep=', ')\n",
        "print('Thousand largest IG features :' )\n",
        "print(*thousand_largest_words,sep=', ')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ten largest IG features :\n",
            "language, remove, free, linguistic, university, money, click, market, our, business\n",
            "Hundred largest IG features :\n",
            "language, remove, free, linguistic, university, money, click, market, our, business, today, advertise, product, company, sell, million, internet, english, income, linguistics, easy, save, guarantee, thousand, best, check, purchase, buy, win, cash, day, over, bulk, want, cost, dollar, every, service, mailing, edu, com, yourself, hundred, papers, earn, linguist, hour, theory, customer, offer, profit, success, fun, month, abstract, here, yours, conference, watch, receive, pay, ever, speaker, credit, bonus, start, zip, sale, amaze, live, discussion, toll, syntax, investment, financial, anywhere, online, department, dream, huge, grammar, friend, simply, science, structure, week, need, wait, deadline, mlm, fresh, study, security, marketing, xxx, ship, analysis, workshop, off, line\n",
            "Thousand largest IG features :\n",
            "language, remove, free, linguistic, university, money, click, market, our, business, today, advertise, product, company, sell, million, internet, english, income, linguistics, easy, save, guarantee, thousand, best, check, purchase, buy, win, cash, day, over, bulk, want, cost, dollar, every, service, mailing, edu, com, yourself, hundred, papers, earn, linguist, hour, theory, customer, offer, profit, success, fun, month, abstract, here, yours, conference, watch, receive, pay, ever, speaker, credit, bonus, start, zip, sale, amaze, live, discussion, toll, syntax, investment, financial, anywhere, online, department, dream, huge, grammar, friend, simply, science, structure, week, need, wait, deadline, mlm, fresh, study, security, marketing, xxx, ship, analysis, workshop, off, line, home, back, instruction, topic, secret, legal, package, profitable, spend, excite, fantastic, immediately, debt, research, keep, step, freedom, net, advertisement, price, delivery, overnight, delete, issue, hello, adult, everything, site, reference, aol, risk, right, again, committee, reply, semantic, discourse, never, development, orders, fill, hit, simple, enter, spam, unlimit, resell, theoretical, once, next, sex, hot, speech, sales, amount, stealth, tax, card, campaign, bill, author, message, tel, return, list, down, love, partner, don, hottest, personal, great, visa, monthly, bank, acquisition, absolutely, capital, aspect, opportunity, phonology, life, amazing, making, plans, undeliverable, computational, big, submission, add, lexical, fax, own, choose, invest, works, video, engine, join, student, cognitive, guaranteed, lottery, per, context, prove, semantics, car, luck, relax, remember, brand, weekly, always, reports, french, nothing, tell, worldwide, effective, exactly, between, try, focus, top, total, refund, retire, put, hobby, hundreds, millions, envelope, generate, summary, decide, lose, affiliation, institute, word, federal, syntactic, future, quick, totally, chance, comply, rate, paper, everyone, faster, super, duplicate, fortune, clean, practically, mail, lists, cent, verb, corporations, dollars, greatest, create, window, seven, even, visit, powerful, sources, construction, morphology, owe, german, mastercard, advantage, competition, sure, completely, billion, sender, april, translation, gamble, enjoy, much, legitimate, extra, suite, expiration, charge, bankruptcy, everythe, paste, john, city, hesitate, excess, mailbox, query, lucky, recruit, mailer, alter, role, miss, invite, true, pragmatic, teen, european, eliminate, trade, order, speak, better, session, researcher, search, evaluating, yahoo, chair, perspective, make, sincerely, programs, quit, afford, wrap, historical, are, truly, vacation, corpus, bottom, plus, august, downline, millionaire, tips, modern, secure, really, evidence, grammatical, junk, deposit, honest, book, programme, incredible, unsubscribe, print, easiest, buyer, sentence, most, pick, signature, away, literature, release, addresses, intrusion, mci, mortgage, scam, worth, imagine, native, wish, aim, roll, girl, formal, code, effort, services, instructions, verify, discuss, law, testimonial, forever, else, submit, stop, datum, succeed, presentation, industry, registration, representation, phone, software, gold, capitalfm, cleanest, earnings, fabulous, instant, overload, constraint, filter, interaction, ticket, general, relevant, hours, modem, description, approach, shop, trial, family, academic, sit, society, organize, protect, tip, enterprise, beach, easily, game, piece, accurately, fast, let, astonishment, cram, creditor, numbers, reg, released, sexually, staggering, totals, dialect, movie, pass, name, instruct, rom, publication, germany, many, variety, ordering, protection, forget, believer, marketer, raleigh, started, vanish, culture, present, speed, theme, did, believe, discover, relation, accountant, conceal, limited, upgrade, financially, laugh, doubt, run, earth, real, proof, automatically, alone, entire, please, latest, notification, corporation, phonological, sociolinguistic, anytime, desirous, entrepreneur, estate, fairchild, grumble, juno, merciless, spokane, spout, unlimited, webmaster, someone, before, allow, isp, waste, lexicon, hardcore, lawful, rights, batch, ours, retirement, letter, extraordinary, fraction, unsolicit, argument, yes, help, pattern, contribution, download, perfectly, air, particular, comparative, van, interpretation, natural, server, dupe, esq, rockland, stun, weeks, read, introduction, framework, below, owner, additional, advertiser, compliance, extractor, genie, amateur, penny, revenue, sent, wall, gov, clearance, days, reap, office, cambridge, increase, qualify, alway, client, faith, spanish, payable, professional, unique, boy, magazine, france, proceedings, little, news, chat, length, cultural, type, welcome, turn, noun, report, request, percentage, whatsoever, leave, awesome, prepared, privacy, prodigy, refinance, removed, retail, rip, robbery, selle, thousands, inexpensive, quickly, complex, mit, bet, color, toy, potential, store, association, among, blvd, affordable, mclaughlin, savings, anything, ram, rat, removal, trash, action, shock, expression, phonetic, daily, march, editor, professor, bin, less, isbn, variation, acceptance, proposal, access, reach, postage, show, lot, principle, gift, rush, boyfriend, celebrity, classified, emailer, filled, living, msn, premium, secrets, lifetime, persistent, skeptical, article, each, particularly, exclusive, richer, faculty, chinese, provider, japanese, already, button, convenience, tremendous, benefits, blast, casino, instantly, meg, residual, robert, cds, confidential, dial, goods, dictionary, info, centre, thing, high, sexual, proud, winner, golden, chapter, cross, after, hold, until, soon, why, almost, ling, state, low, operate, file, david, text, argue, immediate, second, february, participate, dissertation, entertainment, hotmail, jackson, lanse, addressed, biz, included, inflation, pile, porn, seller, someday, stamped, vulgarity, wilburn, morphological, notion, application, ahead, jump, trust, amex, cyber, illegal, legally, happen, cut, enclose, case, style, cable, countless, embark, fastest, through, parallel, uni, carefully, deliver, recent, exact, graduate, small, ease, berlin, colleague, dept, test, move, project, few, clause, distinction, lecture, promotion, stock, expensive, netherland, early, michael, require, bel, newsgroup, obligation, thereafter, hand, june, logic, vowel, model, recipient, wealth, job, goal, obviously, average, cgi, recieve, billboard, catchy, divorce, downpayment, flamer, instructed, mega, murkowskus, overflow, pic, poorer, profanity, recession, unproductive, wisely, psycholinguistic, scholar, symposium, extremely, grow, asset, awhile, continual, criminal, goodness, promptly, upset, rather, phrase, adults, girlfriend, postmaster, proven, trail, unemployment, everyday, biggest, der, organizer, mark, promise, largest, loan, kid, radio, error, central, discipline, rich, within, teacher, consist, successful, flame, human, accommodation, using, term, campus, empirical, journal, object, compuserve, utility, payment, publish, convince, september, address, camera, jame, email, satisfy, bargain, competitor, gay, mouse, paradise, sleep, conservative, race, cloth, dutch, install, correctly, happy, gain, excellent, postscript, japan, bit, insurance, pop, cheap, comfort, consumer, dare, driver, manufacturer, moment, school, oxford, peter, answer, dave, multi, hall, star, bad, highway, husband, launch, generative, assuming, authenticate, cards, checks, commercialemail, commercialize, mba, moving, originator, platinum, profits, promotional, requesting, respectability, sexiest, unforeseen, vcs, patient, prompt, trouble, album, bull, exp, fortunately, kitchen, muncie, permanently, wealthy, extend, martin, record, beautiful, post, anon, banner, cum, delphus, erotic, exceedingly, favourite, friends, define, methodology, various, clothe, solid, implication, psychology, scientific, november, stay, boss, dramatically, supplies, announcement, television, verbal, univ, volume, surely, thank, apply, encourage, achieve, box, manual, digital, discount, global, functional, dori, mil, password, photo, weekend, laboratory, phonetics, preliminary, proceeding, fulfill, imagination, reward, without, concern, portion, function, pennsylvanium, typology, phillip, copyright, represent, guide, philosophy, rest, holiday, initially, social, prof, derive, two, produce, basically, effect, suggest, abuse, required, txt, identify, dialogue, gender, organise\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ3ldtiyQ950"
      },
      "source": [
        "# Naive Bayes- Part2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuXnd-6QRdB-"
      },
      "source": [
        "accuracy_df = pd.DataFrame(columns=['model','precision','recall'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhsIwJA4-AoN"
      },
      "source": [
        "## Bernoulli Naive Bayes with Binary Features\n",
        "\n",
        "**Please note** the data has already applied Laplacian Smoothing in IG calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZGwGeEJVGQJ"
      },
      "source": [
        "# Function to determine Naive Bayes with Binary Features\n",
        "def predict_binary_BernoulliNB(training_data, test_data, smoothing_applied=True):\n",
        "  predicted_labels = []\n",
        "  global spam_counter\n",
        "  global ham_counter\n",
        "  if not smoothing_applied:\n",
        "    training_data['ham_count'] = training_data['ham_count']+1\n",
        "    training_data['spam_count'] = training_data['spam_count']+1\n",
        "    spam_counter += 2\n",
        "    ham_counter += 2\n",
        "\n",
        "  p_spam = (spam_counter)/(spam_counter+ham_counter)\n",
        "  p_legit = (ham_counter)/(spam_counter+ham_counter)\n",
        "\n",
        "  for i in range(len(test_data)):\n",
        "    test_email = test_data.iloc[i]\n",
        "    p_spam_i = ((training_data['spam_count']/spam_counter)**test_email).prod()\n",
        "    one_minus_p_subi_spam = ((1-(training_data['spam_count']/spam_counter))**(1-test_email)).prod()\n",
        "    p_legit_i = ((training_data['ham_count']/ham_counter)**test_email).prod()\n",
        "    one_minus_p_subi_legit = ((1-(training_data['ham_count']/ham_counter))**(1-test_email)).prod()\n",
        "    probability = (p_spam*p_spam_i*one_minus_p_subi_spam/(p_legit*p_legit_i*one_minus_p_subi_legit)).prod()\n",
        "    if probability>1:\n",
        "      predicted_labels.append(0)\n",
        "    else:\n",
        "      predicted_labels.append(1)\n",
        "  return np.asarray(predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJpeVw_SwuUR"
      },
      "source": [
        "### Ten Largest Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi1DjM4s9h-e",
        "outputId": "db3aae1c-94f2-43db-c8e2-ea5ca768624b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Ten Largest Features\n",
        "training_data = ten_largest.drop(['spam_count','ham_count','IG'], axis = 1).transpose()\n",
        "\n",
        "predicted_NB_binary = predict_binary_BernoulliNB(ten_largest, testing_df[ten_largest.index])\n",
        "\n",
        "# Using inbuilt_library\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X=training_data, y=train_labels)\n",
        "y_BNB_ten = clf.predict(testing_df[ten_largest.index])\n",
        "print(\"Comparing function results to that of  sklearn library.\\nNumber of values that are same: {}. Test dataset length: {}\"\n",
        "      .format((y_BNB_ten==predicted_NB_binary).sum(),len(testing_df)))\n",
        "\n",
        "recall_BNB_ten = recall_score(1-np.array(test_labels),1-predicted_NB_binary)\n",
        "precision_BNB_ten = precision_score(1-np.array(test_labels), 1-predicted_NB_binary)\n",
        "print(\"Bernoulli Naive Bayes with 10 top IG features.\")\n",
        "print(\"Precision: {:.2f}, Recall: {:.2f}\".format(precision_BNB_ten,recall_BNB_ten))\n",
        "accuracy_df = accuracy_df.append({'model':'Bernoulli NB Binary 10 Features', 'precision':precision_BNB_ten,\n",
        "                                  'recall':recall_BNB_ten},ignore_index=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparing function results to that of  sklearn library.\n",
            "Number of values that are same: 291. Test dataset length: 291\n",
            "Bernoulli Naive Bayes with 10 top IG features.\n",
            "Precision: 0.87, Recall: 0.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ2cX14MwzNK"
      },
      "source": [
        "### Hundred Largest Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX490l9Zw2SQ",
        "outputId": "20bd2cc6-891f-4ddf-d2cd-9c8b25bcfe16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Hundred Largest Features\n",
        "predicted_NB_binary_hundred = predict_binary_BernoulliNB(hundred_largest, testing_df[hundred_largest.index])\n",
        "recall_BNB_hundred = recall_score(1-np.array(test_labels),1-predicted_NB_binary_hundred)\n",
        "precision_BNB_hundred = precision_score(1-np.array(test_labels), 1-predicted_NB_binary_hundred)\n",
        "print(\"Bernoulli Naive Bayes with 100 top IG features.\")\n",
        "print(\"Precision:{:.2f}, Recall:{:.2f}\".format(precision_BNB_hundred,recall_BNB_hundred))\n",
        "accuracy_df = accuracy_df.append({'model':'Bernoulli NB Binary 100 Features', 'precision':precision_BNB_hundred,\n",
        "                                  'recall':recall_BNB_hundred},ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bernoulli Naive Bayes with 100 top IG features.\n",
            "Precision:1.00, Recall:0.67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiBg1Sr4w49w"
      },
      "source": [
        "### Thousand Largest Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcNzpd5Dw8bO",
        "outputId": "a5b9a1e5-abcd-46b6-bbe5-7f834fcabc27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Thousand Largest Features\n",
        "predicted_NB_binary_thousand = predict_binary_BernoulliNB(thousand_largest, testing_df[thousand_largest.index])\n",
        "recall_BNB_thousand = recall_score(1-np.array(test_labels),1-predicted_NB_binary_thousand)\n",
        "precision_BNB_thousand = precision_score(1-np.array(test_labels),1-predicted_NB_binary_thousand)\n",
        "print(\"Bernoulli Naive Bayes with 1000 top IG features.\")\n",
        "print(\"Precision:{:.2f}, Recall:{:.2f}\".format(precision_BNB_thousand,recall_BNB_thousand))\n",
        "accuracy_df = accuracy_df.append({'model':'Bernoulli NB Binary 1000 Features', 'precision':precision_BNB_thousand,\n",
        "                                  'recall':recall_BNB_thousand},ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bernoulli Naive Bayes with 1000 top IG features.\n",
            "Precision:1.00, Recall:0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waVyTLEELpbT"
      },
      "source": [
        "## Multinomial Naive Bayes with Binary Features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVFr9X5lZ03L"
      },
      "source": [
        "# Function to determine multinomial Naive Bayes.\n",
        "def predict_multinomial_NB(training_data, test_data, smoothing_applied = True):\n",
        "  predicted_labels = []\n",
        "  global spam_counter\n",
        "  global ham_counter\n",
        "  # the global values have been smoothed already\n",
        "  if not smoothing_applied:\n",
        "    training_data['ham_count'] = training_data['ham_count']+1\n",
        "    training_data['spam_count'] = training_data['spam_count']+1\n",
        "\n",
        "  p_spam = (spam_counter)/(spam_counter+ham_counter)\n",
        "  p_legit = (ham_counter)/(spam_counter+ham_counter)\n",
        "  summation_M_spam = training_data['spam_count'].sum()\n",
        "  summation_M_legit = training_data['ham_count'].sum()\n",
        "\n",
        "  for i in range(len(test_data)):\n",
        "    test_email = test_data.iloc[i]\n",
        "    p_spam_i = ((training_data['spam_count']/summation_M_spam)**test_email).prod()\n",
        "    p_legit_i = ((training_data['ham_count']/summation_M_legit)**test_email).prod()\n",
        "    probability = (p_spam*p_spam_i/(p_legit*p_legit_i)).prod()\n",
        "    if probability>1:\n",
        "      predicted_labels.append(0)\n",
        "    else:\n",
        "      predicted_labels.append(1)\n",
        "\n",
        "  return np.asarray(predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSJKDqKmiK0O"
      },
      "source": [
        "### Ten Largest Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXsNkEHMiN-q",
        "outputId": "25f93308-5fdc-4c99-bf13-56b7805611df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Ten Largest Features\n",
        "training_data = ten_largest.drop(['spam_count','ham_count','IG'], axis = 1).transpose()\n",
        "\n",
        "predicted_NB_multinomial = predict_multinomial_NB(ten_largest, testing_df[ten_largest.index])\n",
        "\n",
        "# Using inbuilt_library\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X=training_data, y=train_labels)\n",
        "y_MNB_ten = clf.predict(testing_df[ten_largest.index])\n",
        "print(\"Comparing function results to that of  sklearn library.\\nNumber of values that are same: {}. Test dataset length: {}\"\n",
        "      .format((y_BNB_ten==predicted_NB_multinomial).sum(),len(testing_df)))\n",
        "\n",
        "recall_MNB_ten = recall_score(1-np.array(test_labels),1-predicted_NB_multinomial)\n",
        "precision_MNB_ten = precision_score(1-np.array(test_labels), 1-predicted_NB_multinomial)\n",
        "print(\"Multinomial binary features Naive Bayes with 10 top IG features.\")\n",
        "print(\"Precision: {:.2f}, Recall: {:.2f}\".format(precision_MNB_ten,recall_MNB_ten))\n",
        "accuracy_df = accuracy_df.append({'model':'Multinomial NB Binary 10 Features', 'precision':precision_MNB_ten,\n",
        "                                  'recall':recall_MNB_ten},ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparing function results to that of  sklearn library.\n",
            "Number of values that are same: 290. Test dataset length: 291\n",
            "Multinomial binary features Naive Bayes with 10 top IG features.\n",
            "Precision: 0.89, Recall: 0.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2AXr1KhLMrJ"
      },
      "source": [
        "### Hundred Largest Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-8JwyAfLT2-",
        "outputId": "77f3869d-08fb-4355-ba38-0f67e6dbd425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predicted_NB_multinomial_hundred = predict_multinomial_NB(hundred_largest, testing_df[hundred_largest.index])\n",
        "\n",
        "recall_MNB_hundred = recall_score(1-np.array(test_labels),1-predicted_NB_multinomial_hundred)\n",
        "precision_MNB_hundred = precision_score(1-np.array(test_labels), 1-predicted_NB_multinomial_hundred)\n",
        "print(\"Multinomial binary features Naive Bayes with 100 top IG features.\")\n",
        "print(\"Precision: {:.2f}, Recall: {:.2f}\".format(precision_MNB_hundred,recall_MNB_hundred))\n",
        "accuracy_df = accuracy_df.append({'model':'Multinomial NB Binary 100 Features', 'precision':precision_MNB_hundred,\n",
        "                                  'recall':recall_MNB_hundred},ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial binary features Naive Bayes with 100 top IG features.\n",
            "Precision: 0.96, Recall: 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOZhqUmzL8fE"
      },
      "source": [
        "### Thousand Largest Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v55NmFBMLku",
        "outputId": "c019bc03-ed89-4696-f6ad-ad1ad62e4fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predicted_NB_multinomial_thousand = predict_multinomial_NB(thousand_largest, testing_df[thousand_largest.index])\n",
        "\n",
        "recall_MNB_thousand = recall_score(1-np.array(test_labels),1-predicted_NB_multinomial_thousand)\n",
        "precision_MNB_thousand = precision_score(1-np.array(test_labels), 1-predicted_NB_multinomial_thousand)\n",
        "print(\"Multinomial binary features Naive Bayes with 1000 top IG features.\")\n",
        "print(\"Precision: {:.2f}, Recall: {:.2f}\".format(precision_MNB_thousand,recall_MNB_thousand))\n",
        "accuracy_df = accuracy_df.append({'model':'Multinomial NB Binary 1000 Features', 'precision':precision_MNB_thousand,\n",
        "                                  'recall':recall_MNB_thousand},ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial binary features Naive Bayes with 1000 top IG features.\n",
            "Precision: 1.00, Recall: 0.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIyNFWYjNIrw"
      },
      "source": [
        "## Multinomial Naive Bayes with Term Frequencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR6wLvYQNRir"
      },
      "source": [
        "# First assigning IG to retrieve top 10,100,1000 largest df\n",
        "tf_df['IG'] = document_df['IG']\n",
        "ten_largest_tf = tf_df.nlargest(10,'IG')\n",
        "hundred_largest_tf = tf_df.nlargest(100,'IG')\n",
        "thousand_largest_tf = tf_df.nlargest(1000,'IG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gwXytWYOGRb"
      },
      "source": [
        "### Ten Largest Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqs5O6G3MoR_",
        "outputId": "be590b3f-4599-49c4-c5dc-cb011ecd8fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predicted_NB_multinomial_tf = predict_multinomial_NB(ten_largest_tf, tf_testing_df[ten_largest_tf.index], False)\n",
        "\n",
        "recall_MNB_ten_tf = recall_score(1-np.array(test_labels),1-predicted_NB_multinomial_tf)\n",
        "precision_MNB_ten_tf = precision_score(1-np.array(test_labels), 1-predicted_NB_multinomial_tf)\n",
        "print(\"Multinomial TF features Naive Bayes with 10 top IG features.\")\n",
        "print(\"Precision: {:.2f}, Recall: {:.2f}\".format(precision_MNB_ten_tf,recall_MNB_ten_tf))\n",
        "accuracy_df = accuracy_df.append({'model':'Multinomial NB TF 10 Features', 'precision':precision_MNB_ten_tf,\n",
        "                                  'recall':recall_MNB_ten_tf},ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial TF features Naive Bayes with 10 top IG features.\n",
            "Precision: 0.85, Recall: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6irIVgEYPQMf"
      },
      "source": [
        "### Hundred Largest Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr2y4Xf9O1qe",
        "outputId": "843aef9f-c4f2-4c8d-c0c1-92772c1103ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predicted_NB_multinomial_hundred_tf = predict_multinomial_NB(hundred_largest_tf, tf_testing_df[hundred_largest_tf.index],False)\n",
        "\n",
        "recall_MNB_hundred_tf = recall_score(1-np.array(test_labels),1-predicted_NB_multinomial_hundred_tf)\n",
        "precision_MNB_hundred_tf = precision_score(1-np.array(test_labels), 1-predicted_NB_multinomial_hundred_tf)\n",
        "print(\"Multinomial TF features Naive Bayes with 100 top IG features.\")\n",
        "print(\"Precision: {:.2f}, Recall: {:.2f}\".format(precision_MNB_hundred_tf,recall_MNB_hundred_tf))\n",
        "accuracy_df = accuracy_df.append({'model':'Multinomial NB TF 100 Features', 'precision':precision_MNB_hundred_tf,\n",
        "                                  'recall':recall_MNB_hundred_tf},ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial TF features Naive Bayes with 100 top IG features.\n",
            "Precision: 0.96, Recall: 0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTU0iO9uPTrD"
      },
      "source": [
        "### Thousand Largest Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOn8PTvtNyXi",
        "outputId": "67e0013c-45d7-457f-9dd0-0c486a52f6f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predicted_NB_multinomial_thousand_tf = predict_multinomial_NB(thousand_largest_tf, tf_testing_df[thousand_largest.index], False)\n",
        "\n",
        "recall_MNB_thousand_tf = recall_score(1-np.array(test_labels),1-predicted_NB_multinomial_thousand_tf)\n",
        "precision_MNB_thousand_tf = precision_score(1-np.array(test_labels), 1-predicted_NB_multinomial_thousand_tf)\n",
        "print(\"Multinomial TF Naive Bayes with 1000 top IG features.\")\n",
        "print(\"Precision: {:.2f}, Recall: {:.2f}\".format(precision_MNB_thousand_tf,recall_MNB_thousand_tf))\n",
        "accuracy_df = accuracy_df.append({'model':'Multinomial NB TF 1000 Features', 'precision':precision_MNB_thousand_tf,\n",
        "                                  'recall':recall_MNB_thousand_tf},ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial TF Naive Bayes with 1000 top IG features.\n",
            "Precision: 1.00, Recall: 0.67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTNAqCYDUYmO"
      },
      "source": [
        "## Precision and Recall Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNg_GcfKUTlY",
        "outputId": "286e638c-0c18-425e-ecf3-62e54f60b136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(accuracy_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 model  precision    recall\n",
            "0      Bernoulli NB Binary 10 Features   0.869565  0.816327\n",
            "1     Bernoulli NB Binary 100 Features   1.000000  0.673469\n",
            "2    Bernoulli NB Binary 1000 Features   1.000000  0.612245\n",
            "3    Multinomial NB Binary 10 Features   0.888889  0.816327\n",
            "4   Multinomial NB Binary 100 Features   0.957447  0.918367\n",
            "5  Multinomial NB Binary 1000 Features   1.000000  0.836735\n",
            "6        Multinomial NB TF 10 Features   0.851852  0.938776\n",
            "7       Multinomial NB TF 100 Features   0.959184  0.959184\n",
            "8      Multinomial NB TF 1000 Features   1.000000  0.673469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJKXKb5QW4U4"
      },
      "source": [
        "#SVM- Part3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrER0vXnfAXK"
      },
      "source": [
        "### Data Definition\n",
        "Since we will be using the entire dataset with cross validation, creating a new dataset as the combination of both training and testing dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQn5OVzQe_6L"
      },
      "source": [
        "# Recovering the original dataset from the training and testing dataframes.\n",
        "training_data = document_df.drop(['spam_count','ham_count','IG'],axis=1).transpose().append(testing_df,ignore_index=True)\n",
        "\n",
        "# Doing 1 - labels to flip the labels and have 0 represent ham, 1 represent spam. \n",
        "# All previous experiments were run with the basis that 1 represents ham, 0 represent spam. \n",
        "labels = 1-np.array(train_labels+test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlytGhaHo1Gw"
      },
      "source": [
        "### Model Evaluation\n",
        "\n",
        "We will be using IG to select top features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDXDzpAMcDEV"
      },
      "source": [
        "# Using 5 consecutive crossvalidated scores\n",
        "def evaluate_svm(model, X, y, splits = 5):\n",
        "  scores = cross_val_score(model, X, y, cv = splits)\n",
        "  return scores\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdmxAPgwjFx8",
        "outputId": "31512e3e-096c-42c3-8aa3-21f39b02c199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "SVM_accuracy = pd.DataFrame(columns=['model', 'number_of_features', 'accuracy_mean', 'accuracy_std'])\n",
        "features = {10:ten_largest.index, 100:hundred_largest.index, 1000:thousand_largest.index}\n",
        "for kernel in kernels:\n",
        "  model = SVC(kernel=kernel)\n",
        "  for number in features:\n",
        "    scores = evaluate_svm(model, training_data[features[number]], train_labels+test_labels)\n",
        "    SVM_accuracy = SVM_accuracy.append({'model':'SVM {} kernel'.format(kernel), 'accuracy_mean':scores.mean(), \n",
        "                        'accuracy_std':scores.std(),'number_of_features': number},ignore_index=True)\n",
        "  \n",
        "print('The model accuracies are shown below:')\n",
        "print(SVM_accuracy)\n",
        "print('\\n\\nThe best model scores are given by:')\n",
        "print(SVM_accuracy[SVM_accuracy['accuracy_mean']==SVM_accuracy['accuracy_mean'].max()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracies are shown below:\n",
            "                 model number_of_features  accuracy_mean  accuracy_std\n",
            "0    SVM linear kernel                 10       0.963359      0.007128\n",
            "1    SVM linear kernel                100       0.980987      0.007737\n",
            "2    SVM linear kernel               1000       0.986518      0.007609\n",
            "3      SVM poly kernel                 10       0.960589      0.013866\n",
            "4      SVM poly kernel                100       0.938123      0.004741\n",
            "5      SVM poly kernel               1000       0.898025      0.014808\n",
            "6       SVM rbf kernel                 10       0.965430      0.008345\n",
            "7       SVM rbf kernel                100       0.984099      0.006417\n",
            "8       SVM rbf kernel               1000       0.991358      0.002445\n",
            "9   SVM sigmoid kernel                 10       0.935356      0.019702\n",
            "10  SVM sigmoid kernel                100       0.975801      0.010945\n",
            "11  SVM sigmoid kernel               1000       0.984789      0.006511\n",
            "\n",
            "\n",
            "The best model scores are given by:\n",
            "            model number_of_features  accuracy_mean  accuracy_std\n",
            "8  SVM rbf kernel               1000       0.991358      0.002445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehgw5DE3HBgQ"
      },
      "source": [
        "# Adversarial Classification- Part4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDod9mgccEwq"
      },
      "source": [
        "## Baseline classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcjAg1_ob_zh"
      },
      "source": [
        "training_data = ten_largest.drop(['spam_count','ham_count','IG'], axis = 1).transpose()\n",
        "\n",
        "# Using inbuilt_library\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X=training_data, y=train_labels)\n",
        "baseline_predicted = clf.predict(testing_df[ten_largest.index])\n",
        "spam_classified = np.where(baseline_predicted==0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuPlai96CRey"
      },
      "source": [
        "## $LO(x_i)$ on top 10 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpkvfO2NdLiM"
      },
      "source": [
        "def calculate_LO(training_data,testing_data):\n",
        "  LO = np.zeros(10)\n",
        "  LO_compliment = np.zeros(10)\n",
        "  for i in predicted_true_spam:\n",
        "    sample = testing_data.loc[i]\n",
        "    p_spam_i = training_data['spam_count']/spam_counter\n",
        "    p_x_spam = (p_spam_i ** sample)\n",
        "    p_ham_i = training_data['ham_count']/ham_counter\n",
        "    p_x_ham = (p_ham_i ** sample)\n",
        "    LO += np.log2(p_x_spam/p_x_ham)\n",
        "    LO_compliment += np.log2(1-(p_x_spam/p_x_ham))\n",
        "  return LO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjVOiHD9Chwf"
      },
      "source": [
        "training_data = ten_largest\n",
        "training_data['spam_count'] = training_data['spam_count'] + 1\n",
        "training_data['ham_count'] = training_data['ham_count'] + 1\n",
        "testing_data = testing_df[ten_largest.index]\n",
        "predicted_true_spam = np.intersect1d(spam_classified,np.where(np.array(test_labels)==0))\n",
        "testing_data = testing_data.iloc[predicted_true_spam]\n",
        "\n",
        "LO = calculate_LO(training_data, testing_data)\n",
        "LO_compliment = calculate_LO(training_data, 1-testing_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQJLRxcuWuhk"
      },
      "source": [
        "Confirming all $LO(x_i)$ values are positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnZblySPEg8w",
        "outputId": "9324ac33-7600-47e2-a87a-ab68440ec225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(*zip(LO,LO>=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.0, True) (83.74383707620471, True) (79.70818938184435, True) (0.0, True) (0.0, True) (38.342190746372616, True) (84.97894916894892, True) (23.77848954669334, True) (45.73007877092342, True) (23.762492520176533, True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZlExpaDg0br"
      },
      "source": [
        "## Using minimum N words as ADDWORDS and calculating cost. $N\\in[1,3]$\n",
        "\n",
        "Since 3 terms in the LO array equate to 0, we shall use those words as ADDWORDS in all test emails where the term is 0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YKN0TwagPhs"
      },
      "source": [
        "# Since 3 terms are 0 in LO, we shall add these words to the emails.\n",
        "zero_indices = np.where(LO==0) \n",
        "word_indices = ten_largest.index[zero_indices]\n",
        "\n",
        "# helper\n",
        "def sub_lists (l): \n",
        "    base = []   \n",
        "    lists = [base] \n",
        "    for i in range(len(l)): \n",
        "        orig = lists[:] \n",
        "        new = l[i] \n",
        "        for j in range(len(lists)): \n",
        "            lists[j] = lists[j] + [new] \n",
        "        lists = orig + lists \n",
        "          \n",
        "    return lists[1:] \n",
        "word_indices = sub_lists(word_indices)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KXOIZJ5rlO6"
      },
      "source": [
        "adversarial_df = pd.DataFrame(columns=['ADDWORD_indices', 'COST', \n",
        "                                       'False_Negatives_before', 'False_Negatives_after'])\n",
        "# Although this stands for false positive since, spam is denoted by 0, using false positive\n",
        "_, false_positive, _, _ = confusion_matrix(np.array(test_labels), baseline_predicted).ravel()\n",
        "for indices in word_indices:\n",
        "  temp_test = testing_df[ten_largest.index]\n",
        "  temp_test[indices] = 1\n",
        "  predicted = clf.predict(temp_test)\n",
        "  LO_temp = calculate_LO(training_data, temp_test)\n",
        "  #LO_compliment_temp = calculate_LO(training_data,1-temp_test)\n",
        "  cost = max(np.sum(LO_temp),0)\n",
        "  _, fp, _, _ = confusion_matrix(np.array(test_labels), predicted).ravel()\n",
        "  adversarial_df = adversarial_df.append({'ADDWORD_indices':indices, 'COST':cost,\n",
        "                                          'False_Negatives_before':false_positive, \n",
        "                                          'False_Negatives_after':fp},ignore_index=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHZJW98BG1vB",
        "outputId": "e8b3eaa0-9170-414f-9982-f9766d2fbfcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "adversarial_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADDWORD_indices</th>\n",
              "      <th>COST</th>\n",
              "      <th>False_Negatives_before</th>\n",
              "      <th>False_Negatives_after</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[22426]</td>\n",
              "      <td>183.019742</td>\n",
              "      <td>9</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[23322]</td>\n",
              "      <td>128.373259</td>\n",
              "      <td>9</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[22426, 23322]</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[41630]</td>\n",
              "      <td>230.499505</td>\n",
              "      <td>9</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[22426, 41630]</td>\n",
              "      <td>35.995130</td>\n",
              "      <td>9</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[23322, 41630]</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[22426, 23322, 41630]</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ADDWORD_indices  ...  False_Negatives_after\n",
              "0                [22426]  ...                     29\n",
              "1                [23322]  ...                     39\n",
              "2         [22426, 23322]  ...                     47\n",
              "3                [41630]  ...                     25\n",
              "4         [22426, 41630]  ...                     43\n",
              "5         [23322, 41630]  ...                     47\n",
              "6  [22426, 23322, 41630]  ...                     49\n",
              "\n",
              "[7 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkYuEsszx2xx"
      },
      "source": [
        "## Classifier updation strategy\n",
        "To do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXlNVZTEU8pE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}